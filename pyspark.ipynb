{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8606089f",
   "metadata": {
    "id": "8606089f"
   },
   "source": [
    "### Pyspark Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69ec23f",
   "metadata": {
    "id": "d69ec23f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "#importing pyspark functions\n",
    "from pyspark.sql.functions import col,isnan, when, count,sum\n",
    "import os\n",
    "import sys\n",
    "# Creating SparkSession \n",
    "# Creating SparkSession \n",
    "# building session\n",
    "#setting execution memory size 4gb\n",
    "# setting driver memory size 4gb\n",
    "# setting heap size 50gb\n",
    "#enabling spark executor \n",
    "# selecting all cores to use\n",
    "# setting the pyspark app name\n",
    "# create session or get it if it exists\n",
    "spark = SparkSession.builder \\\n",
    ".config('spark.executer.memory','4g') \\\n",
    ".config('spark.driver.memory','4g') \\\n",
    ".config('spark.offHeap.size','50g') \\\n",
    ".config('spark.executer.enabled','true') \\\n",
    ".appName(\"bigdata\")\\\n",
    ".getOrCreate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca7a939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+------------+----------+----------------+--------+---------+---------+------------+----------------+----------+------------------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             _c0|          _c1|           _c2|         _c3|       _c4|             _c5|     _c6|      _c7|      _c8|         _c9|            _c10|      _c11|              _c12|                _c13|                _c14|                _c15|        _c16|                _c17|                _c18|                _c19|                _c20|                _c21|                _c22|\n",
      "+----------------+-------------+--------------+------------+----------+----------------+--------+---------+---------+------------+----------------+----------+------------------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          Job Id|   Experience|Qualifications|Salary Range|  location|         Country|latitude|longitude|Work Type|Company Size|Job Posting Date|Preference|    Contact Person|             Contact|           Job Title|                Role|  Job Portal|     Job Description|            Benefits|              skills|    Responsibilities|             Company|     Company Profile|\n",
      "|1089843540111562|5 to 15 Years|        M.Tech|   $59K-$99K|   Douglas|     Isle of Man| 54.2361|  -4.5481|   Intern|       26801|      2022-04-24|    Female|Brandon Cunningham|001-381-930-7517x737|Digital Marketing...|Social Media Manager|    Snagajob|Social Media Mana...|{'Flexible Spendi...|Social media plat...|Manage and grow s...|   Icahn Enterprises|\"{\"\"Sector\"\":\"\"Di...|\n",
      "| 398454096642776|2 to 12 Years|           BCA|  $56K-$116K|  Ashgabat|    Turkmenistan| 38.9697|  59.5563|   Intern|      100340|      2022-12-19|    Female|  Francisco Larsen|        461-509-4216|       Web Developer|Frontend Web Deve...|    Idealist|Frontend Web Deve...|{'Health Insuranc...|HTML, CSS, JavaSc...|Design and code u...|PNC Financial Ser...|\"{\"\"Sector\"\":\"\"Fi...|\n",
      "| 481640072963533|0 to 12 Years|           PhD|  $61K-$104K|     Macao|Macao SAR, China| 22.1987| 113.5439|Temporary|       84525|      2022-09-14|      Male|       Gary Gibson|          9687619505|  Operations Manager|Quality Control M...|Jobs2Careers|Quality Control M...|{'Legal Assistanc...|Quality control p...|Establish and enf...|United Services A...|\"{\"\"Sector\"\":\"\"In...|\n",
      "| 688192671473044|4 to 11 Years|           PhD|   $65K-$91K|Porto-Novo|           Benin|  9.3077|   2.3158|Full-Time|      129896|      2023-02-25|    Female|        Joy Lucero|+1-820-643-5431x4...|    Network Engineer|Wireless Network ...|    FlexJobs|Wireless Network ...|{'Transportation ...|Wireless network ...|Design, configure...|                Hess|\"{\"\"Sector\"\":\"\"En...|\n",
      "+----------------+-------------+--------------+------------+----------+----------------+--------+---------+---------+------------+----------------+----------+------------------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/ravindrasinghrana/job-description-dataset\n",
    "# 1. Read a CSV and print output to console\n",
    "df_csv = spark.read.csv(\"F:/data/job_descriptions.csv\")\n",
    "df_csv.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f19a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-------------------+----+---------+--------------------+--------------+--------+----------+-----------+--------------------+----------+------------+--------------+--------------------+-------------------+--------------------+-----------+--------------------+--------------------+\n",
      "|             content|     conversationId|                date|                 id|lang|likeCount|               media|mentionedUsers|outlinks|quoteCount|quotedTweet|     renderedContent|replyCount|retweetCount|retweetedTweet|              source|        sourceLabel|           sourceUrl|tcooutlinks|                 url|                user|\n",
      "+--------------------+-------------------+--------------------+-------------------+----+---------+--------------------+--------------+--------+----------+-----------+--------------------+----------+------------+--------------+--------------------+-------------------+--------------------+-----------+--------------------+--------------------+\n",
      "|Support ðŸ‘‡\\n\\n#Fa...|1376739399593910273|2021-03-30T03:33:...|1376739399593910273|  en|        0|                NULL|          NULL|      []|         0|       NULL|Support ðŸ‘‡\\n\\n#Fa...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|         []|https://twitter.c...|{2018-07-08T14:44...|\n",
      "|Supporting farmer...|1376739306287427584|2021-03-30T03:33:...|1376739306287427584|  en|        0|[{NULL, https://p...|          NULL|      []|         0|       NULL|Supporting farmer...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|         []|https://twitter.c...|{2020-11-29T06:40...|\n",
      "|Support farmers i...|1376738704128020488|2021-03-30T03:31:...|1376738704128020488|  en|        0|[{NULL, https://p...|          NULL|      []|         0|       NULL|Support farmers i...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|         []|https://twitter.c...|{2020-11-29T06:40...|\n",
      "|#StopHateAgainstF...|1376738640542400518|2021-03-30T03:30:...|1376738640542400518|  en|        3|                NULL|          NULL|      []|         0|       NULL|#StopHateAgainstF...|         0|           1|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|         []|https://twitter.c...|{2020-09-22T10:45...|\n",
      "|You hate farmers ...|1376738579171344386|2021-03-30T03:30:...|1376738579171344386|  en|        1|                NULL|          NULL|      []|         0|       NULL|You hate farmers ...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|         []|https://twitter.c...|{2021-02-04T12:55...|\n",
      "+--------------------+-------------------+--------------------+-------------------+----+---------+--------------------+--------------+--------+----------+-----------+--------------------+----------+------------+--------------+--------------------+-------------------+--------------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Read a JSON file and print output to console\n",
    "#https://www.kaggle.com/datasets/prathamsharma123/farmers-protest-tweets-dataset-raw-json\n",
    "df_json = spark.read.json(\"F:/data/farmers-protest-tweets-2021-03-5.json\")\n",
    "df_json.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "643c913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|   series_id|step|           timestamp|  anglez|  enmo|event|__index_level_0__|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|08db4255286f|   0|2018-11-05T10:00:...|-30.8453|0.0447| NULL|                0|\n",
      "|08db4255286f|   1|2018-11-05T10:00:...|-34.1818|0.0443| NULL|                1|\n",
      "|08db4255286f|   2|2018-11-05T10:00:...|-33.8771|0.0483| NULL|                2|\n",
      "|08db4255286f|   3|2018-11-05T10:00:...|-34.2821| 0.068| NULL|                3|\n",
      "|08db4255286f|   4|2018-11-05T10:00:...|-34.3858|0.0768| NULL|                4|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/uadithyan/sleep-states-dataset\n",
    "\n",
    "# 3 Read parquet file and print output to console\n",
    "df_parquet = spark.read.parquet(\"F:/data/CMI_sleep_data_updated.parquet\")\n",
    "df_parquet.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b963ed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of Apache Avro Data Source Guide.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF:/data/userdata1.avro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\sql\\readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of Apache Avro Data Source Guide."
     ]
    }
   ],
   "source": [
    "df = spark.read.format('avro').load(\"F:/data/userdata1.avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b6bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+--------------+-------------------+--------+-----+--------------------+--------+--------+--------+--------+-----------+--------+---------+---+----+--------------------+----+------+-----+---------+-------+------+--------+---------+---------+------+----+----+------+----------+-------+----------+--------------------+------------+---------+---------+----------+\n",
      "|_c0|                 id|    conversation_id|    created_at|               date|timezone|place|               tweet|language|hashtags|cashtags| user_id|user_id_str|username|     name|day|hour|                link|urls|photos|video|thumbnail|retweet|nlikes|nreplies|nretweets|quote_url|search|near| geo|source|user_rt_id|user_rt|retweet_id|            reply_to|retweet_date|translate|trans_src|trans_dest|\n",
      "+---+-------------------+-------------------+--------------+-------------------+--------+-----+--------------------+--------+--------+--------+--------+-----------+--------+---------+---+----+--------------------+----+------+-----+---------+-------+------+--------+---------+---------+------+----+----+------+----------+-------+----------+--------------------+------------+---------+---------+----------+\n",
      "|  0|1373819373090050048|1373669212271566858|1.616379037E12|2021-03-22 02:10:37|       0| NULL|@bluemoondance74 ...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  1|  02|https://twitter.c...|  []|    []|    0|     NULL|  False|  2678|     234|      134|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|\n",
      "|  1|1373735946244431873|1373669212271566858|1.616359147E12|2021-03-21 20:39:07|       0| NULL|@NASASpaceflight ...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  7|  20|https://twitter.c...|  []|    []|    0|     NULL|  False|  7967|     535|      570|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|\n",
      "|  2|1373555480870621188|1373328330041229312| 1.61631612E12|2021-03-21 08:42:00|       0| NULL|  @newscientist True|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  7|  08|https://twitter.c...|  []|    []|    0|     NULL|  False| 15510|     539|      409|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|\n",
      "|  3|1373507545315172357|1373263440391864323|1.616304691E12|2021-03-21 05:31:31|       0| NULL|@cleantechnica I ...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  7|  05|https://twitter.c...|  []|    []|    0|     NULL|  False|143476|   10500|    12483|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|\n",
      "|  4|1373492611231535111|1373357995288051718|1.616301131E12|2021-03-21 04:32:11|       0| NULL|@CathieDWood When...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  7|  04|https://twitter.c...|  []|    []|    0|     NULL|  False|  6568|     376|      425|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|\n",
      "+---+-------------------+-------------------+--------------+-------------------+--------+-----+--------------------+--------+--------+--------+--------+-----------+--------+---------+---+----+--------------------+----+------+-----+---------+-------+------+--------+---------+---------+------+----+----+------+----------+-------+----------+--------------------+------------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 Example for broadcast join (Inner join 2 dataframes)\n",
    "from pyspark.sql.functions import broadcast\n",
    "# https://github.com/MainakRepositor/Datasets/tree/master/Elon%20Tweets\n",
    "\n",
    "# Reading 2020.csv into a DataFrame\n",
    "df_2020Tweets = spark.read.csv(\"F:/data/2020.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Reading 2021.csv into a DataFrame\n",
    "df_2021Tweets = spark.read.csv(\"F:/data/2021.csv\", header=True, inferSchema=True)\n",
    "df_2021Tweets.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc19d654-dc66-4f42-92a1-4bb166535dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+--------------+-------------------+--------+-----+--------------------+--------+--------+--------+--------+-----------+--------+---------+---+----+--------------------+----+------+-----+---------+-------+------+--------+---------+---------+------+----+----+------+----------+-------+----------+--------------------+------------+---------+---------+----------+--------------------+\n",
      "|_c0|                 id|    conversation_id|    created_at|               date|timezone|place|               tweet|language|hashtags|cashtags| user_id|user_id_str|username|     name|day|hour|                link|urls|photos|video|thumbnail|retweet|nlikes|nreplies|nretweets|quote_url|search|near| geo|source|user_rt_id|user_rt|retweet_id|            reply_to|retweet_date|translate|trans_src|trans_dest|               tweet|\n",
      "+---+-------------------+-------------------+--------------+-------------------+--------+-----+--------------------+--------+--------+--------+--------+-----------+--------+---------+---+----+--------------------+----+------+-----+---------+-------+------+--------+---------+---------+------+----+----+------+----------+-------+----------+--------------------+------------+---------+---------+----------+--------------------+\n",
      "|  0|1343644462036086785|1343320495127633920|1.609184778E12|2020-12-28 19:46:18|       0| NULL|Entertainment wil...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  1|  19|https://twitter.c...|  []|    []|    0|     NULL|  False| 55085|    2922|     2611|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|                  []|        NULL|     NULL|     NULL|      NULL|Entertainment wil...|\n",
      "|  1|1343619610617077760|1343386617294295040|1.609178853E12|2020-12-28 18:07:33|       0| NULL|@kimpaquette Just...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  1|  18|https://twitter.c...|  []|    []|    0|     NULL|  False|  8631|     601|      314|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|@kimpaquette Just...|\n",
      "|  2|1343608616960491521|1343576442722893825|1.609176231E12|2020-12-28 17:23:51|       0| NULL|@richierichhhhh_ ...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  1|  17|https://twitter.c...|  []|    []|    0|     NULL|  False| 72434|     495|      907|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|@richierichhhhh_ ...|\n",
      "|  3|1343608530998153222|1343320495127633920|1.609176211E12|2020-12-28 17:23:31|       0| NULL|What should Tesla...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  1|  17|https://twitter.c...|  []|    []|    0|     NULL|  False| 33830|    6932|      884|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|                  []|        NULL|     NULL|     NULL|      NULL|What should Tesla...|\n",
      "|  4|1343431408052662273|1343043963096326147|1.609133982E12|2020-12-28 05:39:42|       0| NULL|@PPathole @WSJ Ab...|      en|      []|      []|44196397|   44196397|elonmusk|Elon Musk|  1|  05|https://twitter.c...|  []|    []|    0|     NULL|  False|  2394|     131|       92|     NULL|  None|NULL|NULL|  NULL|      NULL|   NULL|      NULL|[{'screen_name': ...|        NULL|     NULL|     NULL|      NULL|@PPathole @WSJ Ab...|\n",
      "+---+-------------------+-------------------+--------------+-------------------+--------+-----+--------------------+--------+--------+--------+--------+-----------+--------+---------+---+----+--------------------+----+------+-----+---------+-------+------+--------+---------+---------+------+----+----+------+----------+-------+----------+--------------------+------------+---------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# broadcast join\n",
    "joined_df = df_2020Tweets.join(broadcast(df_2021Tweets), df_2020Tweets[\"id\"] == df_2021Tweets[\"id\"], \"inner\")\n",
    "\n",
    "# columns join\n",
    "result_df = joined_df.select(df_2020Tweets[\"*\"], df_2021Tweets[\"tweet\"])\n",
    "\n",
    "# Show DataFrame\n",
    "result_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea703b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|   series_id|step|           timestamp|  anglez|  enmo|event|__index_level_0__|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|08db4255286f|   6|2018-11-05T10:00:...|-30.5134|0.1073| NULL|                6|\n",
      "|08db4255286f|  40|2018-11-05T10:03:...|-31.4288|0.0949| NULL|               40|\n",
      "|08db4255286f|  42|2018-11-05T10:03:...|-28.9712|0.1037| NULL|               42|\n",
      "|08db4255286f|  45|2018-11-05T10:03:...|-26.3368|0.0952| NULL|               45|\n",
      "|08db4255286f|  46|2018-11-05T10:03:...|-27.0645|0.1327| NULL|               46|\n",
      "|08db4255286f|  47|2018-11-05T10:03:...|-29.9288| 0.198| NULL|               47|\n",
      "|08db4255286f|  48|2018-11-05T10:04:...|-29.0845| 0.144| NULL|               48|\n",
      "|08db4255286f|  49|2018-11-05T10:04:...|-29.3285|0.1032| NULL|               49|\n",
      "|08db4255286f|  50|2018-11-05T10:04:...|-27.6283|0.1116| NULL|               50|\n",
      "|08db4255286f|  52|2018-11-05T10:04:...|-25.8617|0.1314| NULL|               52|\n",
      "|08db4255286f|  53|2018-11-05T10:04:...|-25.0372|0.1681| NULL|               53|\n",
      "|08db4255286f|  54|2018-11-05T10:04:...|-25.6563|0.1173| NULL|               54|\n",
      "|08db4255286f|  63|2018-11-05T10:05:...|-26.7203|0.1197| NULL|               63|\n",
      "|08db4255286f|  64|2018-11-05T10:05:...|-22.9393|0.1739| NULL|               64|\n",
      "|08db4255286f|  65|2018-11-05T10:05:...| -24.387|0.0967| NULL|               65|\n",
      "|08db4255286f|  69|2018-11-05T10:05:...|-27.6708|0.0942| NULL|               69|\n",
      "|08db4255286f|  70|2018-11-05T10:05:...|  -26.06| 0.143| NULL|               70|\n",
      "|08db4255286f|  71|2018-11-05T10:05:...|-24.7516|0.1606| NULL|               71|\n",
      "|08db4255286f|  83|2018-11-05T10:06:...|-23.2881| 0.123| NULL|               83|\n",
      "|08db4255286f|  84|2018-11-05T10:07:...|   -23.5|0.1523| NULL|               84|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Example for Filtering the data \n",
    "filtered_df = df_parquet.filter(df_parquet[\"enmo\"] > 0.09)\n",
    "filtered_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723dd042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|   series_id|step|           timestamp|  anglez|  enmo|event|__index_level_0__|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|08db4255286f|  51|2018-11-05T10:04:...|-25.5639|0.0806| NULL|               51|\n",
      "|08db4255286f|  52|2018-11-05T10:04:...|-25.8617|0.1314| NULL|               52|\n",
      "|08db4255286f|  53|2018-11-05T10:04:...|-25.0372|0.1681| NULL|               53|\n",
      "|08db4255286f|  54|2018-11-05T10:04:...|-25.6563|0.1173| NULL|               54|\n",
      "|08db4255286f|  55|2018-11-05T10:04:...| -23.548|0.0768| NULL|               55|\n",
      "|08db4255286f|  56|2018-11-05T10:04:...|-24.7306|0.0833| NULL|               56|\n",
      "|08db4255286f|  57|2018-11-05T10:04:...| -24.477|0.0653| NULL|               57|\n",
      "|08db4255286f|  58|2018-11-05T10:04:...|-24.1588|0.0555| NULL|               58|\n",
      "|08db4255286f|  59|2018-11-05T10:04:...|-24.4506|0.0493| NULL|               59|\n",
      "|08db4255286f|  60|2018-11-05T10:05:...|-21.7202|0.0622| NULL|               60|\n",
      "|08db4255286f|  61|2018-11-05T10:05:...|-25.7528|0.0424| NULL|               61|\n",
      "|08db4255286f|  62|2018-11-05T10:05:...|-24.6424|0.0262| NULL|               62|\n",
      "|08db4255286f|  63|2018-11-05T10:05:...|-26.7203|0.1197| NULL|               63|\n",
      "|08db4255286f|  64|2018-11-05T10:05:...|-22.9393|0.1739| NULL|               64|\n",
      "|08db4255286f|  65|2018-11-05T10:05:...| -24.387|0.0967| NULL|               65|\n",
      "|08db4255286f|  66|2018-11-05T10:05:...|-28.0185|0.0589| NULL|               66|\n",
      "|08db4255286f|  67|2018-11-05T10:05:...|-27.7168|0.0555| NULL|               67|\n",
      "|08db4255286f|  68|2018-11-05T10:05:...|-28.1371|0.0804| NULL|               68|\n",
      "|08db4255286f|  69|2018-11-05T10:05:...|-27.6708|0.0942| NULL|               69|\n",
      "|08db4255286f|  70|2018-11-05T10:05:...|  -26.06| 0.143| NULL|               70|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df1 = df_parquet.filter(df_parquet[\"step\"] > 50)\n",
    "filtered_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "241858ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+\n",
      "|max(enmo)|min(enmo)|          avg(enmo)|\n",
      "+---------+---------+-------------------+\n",
      "|   7.0161|      0.0|0.04428616508921974|\n",
      "+---------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Example for applying aggregate functions like  max, min, avg \n",
    "from pyspark.sql.functions import max, min,avg\n",
    "\n",
    "df_parquet.agg(max(\"enmo\"), min(\"enmo\"), avg(\"enmo\")).show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "419c0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+--------------------+-------------------+----+---------+----------+--------------------+----------+------------+--------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|summary|             content|     conversationId|                date|                 id|lang|likeCount|quoteCount|     renderedContent|replyCount|retweetCount|retweetedTweet|              source|        sourceLabel|           sourceUrl|                 url|\n",
      "+-------+--------------------+-------------------+--------------------+-------------------+----+---------+----------+--------------------+----------+------------+--------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|   NULL|Support ðŸ‘‡\\n\\n#Fa...|1376739399593910273|2021-03-30T03:33:...|1376739399593910273|  en|        0|         0|Support ðŸ‘‡\\n\\n#Fa...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|https://twitter.c...|\n",
      "|   NULL|Supporting farmer...|1376739306287427584|2021-03-30T03:33:...|1376739306287427584|  en|        0|         0|Supporting farmer...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|https://twitter.c...|\n",
      "|   NULL|Support farmers i...|1376738704128020488|2021-03-30T03:31:...|1376738704128020488|  en|        0|         0|Support farmers i...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|https://twitter.c...|\n",
      "|   NULL|#StopHateAgainstF...|1376738640542400518|2021-03-30T03:30:...|1376738640542400518|  en|        3|         0|#StopHateAgainstF...|         0|           1|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|https://twitter.c...|\n",
      "|   NULL|You hate farmers ...|1376738579171344386|2021-03-30T03:30:...|1376738579171344386|  en|        1|         0|You hate farmers ...|         0|           0|          NULL|<a href=\"http://t...|Twitter for Android|http://twitter.co...|https://twitter.c...|\n",
      "+-------+--------------------+-------------------+--------------------+-------------------+----+---------+----------+--------------------+----------+------------+--------------+--------------------+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Example for Read json file with typed schema (without infering the schema) with Structtype, StructField .....\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType,DateType\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"summary\", StringType(), True),\n",
    "    StructField(\"content\", StringType(), True),\n",
    "    StructField(\"conversationId\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"lang\", StringType(), True),\n",
    "    StructField(\"likeCount\", StringType(), True),\n",
    "    StructField(\"quoteCount\", StringType(), True),\n",
    "    StructField(\"renderedContent\", StringType(), True),\n",
    "    StructField(\"replyCount\", StringType(), True),\n",
    "    StructField(\"retweetCount\", StringType(), True),\n",
    "    StructField(\"retweetedTweet\", StringType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"sourceLabel\", StringType(), True),\n",
    "    StructField(\"sourceUrl\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read the JSON file with the specified schema\n",
    "df_json_defined_schema = spark.read.schema(schema).json(\"F:/data/farmers-protest-tweets-2021-03-5.json\")\n",
    "\n",
    "# Show the DataFrame\n",
    "df_json_defined_schema.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fae82618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+--------+------+-----+-----------------+\n",
      "|   series_id|  step|           timestamp|  anglez|  enmo|event|__index_level_0__|\n",
      "+------------+------+--------------------+--------+------+-----+-----------------+\n",
      "|18b61dd5aae8|351840|2018-01-12T01:10:...| 23.8277|   0.0| NULL|           351922|\n",
      "|89bd631d1769|381941|2018-02-07T19:28:...|-61.4476|  0.01| NULL|           382028|\n",
      "|7822ee8fe3ec|393653|2018-09-13T10:59:...|-16.8911|0.0622| NULL|           393740|\n",
      "|67f5fc60e494|235083|2017-11-20T02:45:...|  86.529|   0.0| NULL|           235143|\n",
      "|d5e47b94477e|  6248|2017-11-10T03:40:...| 64.6929|5.0E-4| NULL|             6248|\n",
      "|c68260cc9e8f|136622|2017-10-25T10:15:...|-17.2825|0.0071| NULL|           136657|\n",
      "|7822ee8fe3ec|268128|2018-09-06T04:39:...| -9.6864|   0.0| NULL|           268196|\n",
      "|d5e47b94477e|306182|2017-11-27T11:15:...| -13.269|7.0E-4| NULL|           306259|\n",
      "|72bbd1ac3edf|388907|2017-10-12T00:53:...|-16.3899|0.0077| NULL|           388994|\n",
      "|89bd631d1769|219753|2018-01-29T10:12:...|-41.4812|0.0145| NULL|           219812|\n",
      "|7822ee8fe3ec| 86013|2018-08-26T15:42:...|-55.6227|0.0586| NULL|            86034|\n",
      "|0a96f4993bd7|187507|2018-05-14T06:55:...| 52.0077|   0.0| NULL|           187557|\n",
      "|89bd631d1769| 60130|2018-01-20T04:30:...| 23.0624|   0.0| NULL|            60145|\n",
      "|76237b9406d5| 54810|2017-11-17T20:22:...|-45.1237|0.0764| NULL|            54823|\n",
      "|72bbd1ac3edf|258695|2017-10-04T12:02:...|-36.8376|6.0E-4| NULL|           258760|\n",
      "|483d6545417f|131459|2019-02-12T02:19:...|-33.1149| 0.017| NULL|           131490|\n",
      "|8e32047cbc1f|269248|2017-10-01T06:57:...| 33.4102|0.0037| NULL|           269317|\n",
      "|1087d7b0ff2e| 74888|2018-03-17T21:15:...| 15.8432|1.3833| NULL|            74908|\n",
      "|31011ade7c0a| 42052|2017-08-18T03:09:...|-26.4531|   0.0| NULL|            42060|\n",
      "|0cfc06c129cc|355193|2019-01-07T01:04:...|-48.1249|0.0113| NULL|           355275|\n",
      "+------------+------+--------------------+--------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Example for increase and decrease number of dataframe partitions \n",
    "# Increase partitions\n",
    "df_parquet_increase = df_parquet.repartition(15)\n",
    "df_parquet_increase.show() # show dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03260a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|   series_id|step|           timestamp|  anglez|  enmo|event|__index_level_0__|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "|08db4255286f|   0|2018-11-05T10:00:...|-30.8453|0.0447| NULL|                0|\n",
      "|08db4255286f|   1|2018-11-05T10:00:...|-34.1818|0.0443| NULL|                1|\n",
      "|08db4255286f|   2|2018-11-05T10:00:...|-33.8771|0.0483| NULL|                2|\n",
      "|08db4255286f|   3|2018-11-05T10:00:...|-34.2821| 0.068| NULL|                3|\n",
      "|08db4255286f|   4|2018-11-05T10:00:...|-34.3858|0.0768| NULL|                4|\n",
      "|08db4255286f|   5|2018-11-05T10:00:...|-34.9256|0.0511| NULL|                5|\n",
      "|08db4255286f|   6|2018-11-05T10:00:...|-30.5134|0.1073| NULL|                6|\n",
      "|08db4255286f|   7|2018-11-05T10:00:...|-30.5094|0.0649| NULL|                7|\n",
      "|08db4255286f|   8|2018-11-05T10:00:...|-32.8806|0.0485| NULL|                8|\n",
      "|08db4255286f|   9|2018-11-05T10:00:...| -34.675|0.0462| NULL|                9|\n",
      "|08db4255286f|  10|2018-11-05T10:00:...|-32.3365|0.0797| NULL|               10|\n",
      "|08db4255286f|  11|2018-11-05T10:00:...|-31.3002|0.0719| NULL|               11|\n",
      "|08db4255286f|  12|2018-11-05T10:01:...|-29.0589|0.0588| NULL|               12|\n",
      "|08db4255286f|  13|2018-11-05T10:01:...|-28.2669|0.0581| NULL|               13|\n",
      "|08db4255286f|  14|2018-11-05T10:01:...|-29.6412| 0.047| NULL|               14|\n",
      "|08db4255286f|  15|2018-11-05T10:01:...|-24.5447|0.0401| NULL|               15|\n",
      "|08db4255286f|  16|2018-11-05T10:01:...|-27.4409|0.0452| NULL|               16|\n",
      "|08db4255286f|  17|2018-11-05T10:01:...|-26.9326|  0.04| NULL|               17|\n",
      "|08db4255286f|  18|2018-11-05T10:01:...|-27.2784|0.0624| NULL|               18|\n",
      "|08db4255286f|  19|2018-11-05T10:01:...| -27.458|0.0642| NULL|               19|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decrease partitions\n",
    "df_parquet_decrease = df_parquet.coalesce(2)\n",
    "df_parquet_decrease.show()  # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52e2afef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------------------+--------+------+-----+-----------------+\n",
      "|   series_id|step_renamed|           timestamp|  anglez|  enmo|event|__index_level_0__|\n",
      "+------------+------------+--------------------+--------+------+-----+-----------------+\n",
      "|08db4255286f|           0|2018-11-05T10:00:...|-30.8453|0.0447| NULL|                0|\n",
      "|08db4255286f|           1|2018-11-05T10:00:...|-34.1818|0.0443| NULL|                1|\n",
      "|08db4255286f|           2|2018-11-05T10:00:...|-33.8771|0.0483| NULL|                2|\n",
      "|08db4255286f|           3|2018-11-05T10:00:...|-34.2821| 0.068| NULL|                3|\n",
      "|08db4255286f|           4|2018-11-05T10:00:...|-34.3858|0.0768| NULL|                4|\n",
      "|08db4255286f|           5|2018-11-05T10:00:...|-34.9256|0.0511| NULL|                5|\n",
      "|08db4255286f|           6|2018-11-05T10:00:...|-30.5134|0.1073| NULL|                6|\n",
      "|08db4255286f|           7|2018-11-05T10:00:...|-30.5094|0.0649| NULL|                7|\n",
      "|08db4255286f|           8|2018-11-05T10:00:...|-32.8806|0.0485| NULL|                8|\n",
      "|08db4255286f|           9|2018-11-05T10:00:...| -34.675|0.0462| NULL|                9|\n",
      "|08db4255286f|          10|2018-11-05T10:00:...|-32.3365|0.0797| NULL|               10|\n",
      "|08db4255286f|          11|2018-11-05T10:00:...|-31.3002|0.0719| NULL|               11|\n",
      "|08db4255286f|          12|2018-11-05T10:01:...|-29.0589|0.0588| NULL|               12|\n",
      "|08db4255286f|          13|2018-11-05T10:01:...|-28.2669|0.0581| NULL|               13|\n",
      "|08db4255286f|          14|2018-11-05T10:01:...|-29.6412| 0.047| NULL|               14|\n",
      "|08db4255286f|          15|2018-11-05T10:01:...|-24.5447|0.0401| NULL|               15|\n",
      "|08db4255286f|          16|2018-11-05T10:01:...|-27.4409|0.0452| NULL|               16|\n",
      "|08db4255286f|          17|2018-11-05T10:01:...|-26.9326|  0.04| NULL|               17|\n",
      "|08db4255286f|          18|2018-11-05T10:01:...|-27.2784|0.0624| NULL|               18|\n",
      "|08db4255286f|          19|2018-11-05T10:01:...| -27.458|0.0642| NULL|               19|\n",
      "+------------+------------+--------------------+--------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Example for renaming the column of the dataframe \n",
    "\n",
    "df_parquet_rename = df_parquet.withColumnRenamed(\"step\", \"step_renamed\") # renaming column\n",
    "df_parquet_rename.show()  # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0601136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+--------------------+--------+------+-----+-----------------+-----------------------+\n",
      "|   series_id|step|           timestamp|  anglez|  enmo|event|__index_level_0__|new_enmo_column_percent|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+-----------------------+\n",
      "|08db4255286f|   0|2018-11-05T10:00:...|-30.8453|0.0447| NULL|                0|              4.4700003|\n",
      "|08db4255286f|   1|2018-11-05T10:00:...|-34.1818|0.0443| NULL|                1|              4.4300003|\n",
      "|08db4255286f|   2|2018-11-05T10:00:...|-33.8771|0.0483| NULL|                2|              4.8300004|\n",
      "|08db4255286f|   3|2018-11-05T10:00:...|-34.2821| 0.068| NULL|                3|                    6.8|\n",
      "|08db4255286f|   4|2018-11-05T10:00:...|-34.3858|0.0768| NULL|                4|              7.6800003|\n",
      "|08db4255286f|   5|2018-11-05T10:00:...|-34.9256|0.0511| NULL|                5|                   5.11|\n",
      "|08db4255286f|   6|2018-11-05T10:00:...|-30.5134|0.1073| NULL|                6|                  10.73|\n",
      "|08db4255286f|   7|2018-11-05T10:00:...|-30.5094|0.0649| NULL|                7|              6.4900002|\n",
      "|08db4255286f|   8|2018-11-05T10:00:...|-32.8806|0.0485| NULL|                8|              4.8500004|\n",
      "|08db4255286f|   9|2018-11-05T10:00:...| -34.675|0.0462| NULL|                9|                   4.62|\n",
      "|08db4255286f|  10|2018-11-05T10:00:...|-32.3365|0.0797| NULL|               10|              7.9700003|\n",
      "|08db4255286f|  11|2018-11-05T10:00:...|-31.3002|0.0719| NULL|               11|                   7.19|\n",
      "|08db4255286f|  12|2018-11-05T10:01:...|-29.0589|0.0588| NULL|               12|                   5.88|\n",
      "|08db4255286f|  13|2018-11-05T10:01:...|-28.2669|0.0581| NULL|               13|                   5.81|\n",
      "|08db4255286f|  14|2018-11-05T10:01:...|-29.6412| 0.047| NULL|               14|                    4.7|\n",
      "|08db4255286f|  15|2018-11-05T10:01:...|-24.5447|0.0401| NULL|               15|                   4.01|\n",
      "|08db4255286f|  16|2018-11-05T10:01:...|-27.4409|0.0452| NULL|               16|                   4.52|\n",
      "|08db4255286f|  17|2018-11-05T10:01:...|-26.9326|  0.04| NULL|               17|                    4.0|\n",
      "|08db4255286f|  18|2018-11-05T10:01:...|-27.2784|0.0624| NULL|               18|                   6.24|\n",
      "|08db4255286f|  19|2018-11-05T10:01:...| -27.458|0.0642| NULL|               19|                   6.42|\n",
      "+------------+----+--------------------+--------+------+-----+-----------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. Example for adding a new column to the dataframe \n",
    "\n",
    "df_parquet_addcolumn = df_parquet\n",
    "df_parquet_addcolumn = df_parquet.withColumn(\"new_enmo_column_percent\", col(\"enmo\") * 100) # new enmo percentange column \n",
    "df_parquet_addcolumn.show()  # show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a34d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- series_id: string (nullable = true)\n",
      " |-- step: long (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- anglez: float (nullable = true)\n",
      " |-- enmo: float (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Changing the structure of the dataframe\n",
    "df_parquet.printSchema() # printing schema of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "649ba489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-----+-----------------+\n",
      "|step|  anglez|  enmo|event|__index_level_0__|\n",
      "+----+--------+------+-----+-----------------+\n",
      "|   0|-30.8453|0.0447| NULL|                0|\n",
      "|   1|-34.1818|0.0443| NULL|                1|\n",
      "|   2|-33.8771|0.0483| NULL|                2|\n",
      "|   3|-34.2821| 0.068| NULL|                3|\n",
      "|   4|-34.3858|0.0768| NULL|                4|\n",
      "|   5|-34.9256|0.0511| NULL|                5|\n",
      "|   6|-30.5134|0.1073| NULL|                6|\n",
      "|   7|-30.5094|0.0649| NULL|                7|\n",
      "|   8|-32.8806|0.0485| NULL|                8|\n",
      "|   9| -34.675|0.0462| NULL|                9|\n",
      "|  10|-32.3365|0.0797| NULL|               10|\n",
      "|  11|-31.3002|0.0719| NULL|               11|\n",
      "|  12|-29.0589|0.0588| NULL|               12|\n",
      "|  13|-28.2669|0.0581| NULL|               13|\n",
      "|  14|-29.6412| 0.047| NULL|               14|\n",
      "|  15|-24.5447|0.0401| NULL|               15|\n",
      "|  16|-27.4409|0.0452| NULL|               16|\n",
      "|  17|-26.9326|  0.04| NULL|               17|\n",
      "|  18|-27.2784|0.0624| NULL|               18|\n",
      "|  19| -27.458|0.0642| NULL|               19|\n",
      "+----+--------+------+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# droping columns\n",
    "df_parquet_modified = df_parquet.drop(\"timestamp\").drop(\"series_id\") # droping 2 columns\n",
    "\n",
    "# modify enmo from float to sring type\n",
    "df_parquet_modified = df_parquet_modified.withColumn(\"enmo\", col(\"enmo\").cast(StringType())) # modify enmo int data type to string\n",
    "df_parquet_modified.show()  # show dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dc27316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: long (nullable = true)\n",
      " |-- anglez: float (nullable = true)\n",
      " |-- enmo: string (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe the DataFrame\n",
    "df_parquet_modified.printSchema() # print schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "733d7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON data as provided (corrected format)\n",
    "json_data = [\n",
    "    '{\"name\" : \"john doe\", \"dob\" : \"01-01-1970\", \"phone\" : \"+234567890\", \"salary\" : 57000, \"location\" : \"New York\", \"sex\" : \"male\"}',\n",
    "    '{\"name\" : \"john adam\", \"dob\" : \"02-01-1990\", \"phone\" : \"+6634567890\", \"salary\" : 69000, \"location\" : \"Los Angeles\", \"sex\" : \"male\"}',\n",
    "    '{\"name\" : \"jane frank\", \"dob\" : \"01-11-1999\", \"phone\" : \"+9876543210\", \"salary\" : 70000, \"location\" : \"Chicago\", \"sex\" : \"female\"}',\n",
    "    '{\"name\" : \"alice hillary\", \"dob\" : \"01-12-1975\",\"phone\" :\"+4534567890\", \"salary\" : 80000, \"location\" : \"Houston\", \"sex\" : \"female\"}',\n",
    "    '{\"name\" : \"bob kim\", \"dob\" : \"01-01-1985\", \"phone\" : \"+5675555555\", \"salary\" : 10000, \"location\" : \"Phoenix\", \"sex\" : \"male\"}',\n",
    "    '{\"name\" : \"felister malito\", \"dob\" : \"01-01-1995\", \"phone\" : \"+9234567890\", \"salary\" : 65000, \"location\" : \"San Francisco\", \"sex\" : \"male\"}',\n",
    "    '{\"name\" : \"davison steve\", \"dob\" : \"05-01-1970\", \"phone\" : \"+299834444\", \"salary\" : 75000, \"location\" : \"Miami\", \"sex\" : \"male\"}',\n",
    "    '{\"name\" : \"emmanuel pinner\", \"dob\" : \"06-01-1982\", \"phone\" : \"+541293333\", \"salary\" : 82000, \"location\" : \"Boston\", \"sex\" : \"female\"}',\n",
    "    '{\"name\" : \"frank omega\", \"dob\" : \"01-08-1978\", \"phone\" : \"+5673885674\", \"salary\" : 78000, \"location\" : \"Denver\", \"sex\" : \"male\"}',\n",
    "    '{\"name\" : \"gaddiom tom\", \"dob\" : \"01-09-1992\", \"phone\" : \"+6754377779\", \"salary\" : 97000, \"location\" : \"Seattle\", \"sex\" : \"female\"}'\n",
    "]\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_json, struct, lit\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"JSON\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8202fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to RDD\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(json_data) # rdd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86dd7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for JSON\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType,DateType # importing packages\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"dob\", StringType(), True),\n",
    "    StructField(\"phone\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0000c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RDD to DataFrame\n",
    "rdddf = spark.read.json(rdd, schema=schema)\n",
    "\n",
    "\n",
    "# Create a nested structure\n",
    "from pyspark.sql.functions import struct\n",
    "# Restructure DataFrame using struct function and to_json\n",
    "df_restructured = rdddf.select(to_json(struct(\n",
    "    struct(col(\"name\"), col(\"dob\"), col(\"phone\")).alias(\"personal_data\")\n",
    ")).alias(\"json_string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74fb0e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+\n",
      "|json_string                                                                          |\n",
      "+-------------------------------------------------------------------------------------+\n",
      "|{\"personal_data\":{\"name\":\"john doe\",\"dob\":\"01-01-1970\",\"phone\":\"+234567890\"}}        |\n",
      "|{\"personal_data\":{\"name\":\"john adam\",\"dob\":\"02-01-1990\",\"phone\":\"+6634567890\"}}      |\n",
      "|{\"personal_data\":{\"name\":\"jane frank\",\"dob\":\"01-11-1999\",\"phone\":\"+9876543210\"}}     |\n",
      "|{\"personal_data\":{\"name\":\"alice hillary\",\"dob\":\"01-12-1975\",\"phone\":\"+4534567890\"}}  |\n",
      "|{\"personal_data\":{\"name\":\"bob kim\",\"dob\":\"01-01-1985\",\"phone\":\"+5675555555\"}}        |\n",
      "|{\"personal_data\":{\"name\":\"felister malito\",\"dob\":\"01-01-1995\",\"phone\":\"+9234567890\"}}|\n",
      "|{\"personal_data\":{\"name\":\"davison steve\",\"dob\":\"05-01-1970\",\"phone\":\"+299834444\"}}   |\n",
      "|{\"personal_data\":{\"name\":\"emmanuel pinner\",\"dob\":\"06-01-1982\",\"phone\":\"+541293333\"}} |\n",
      "|{\"personal_data\":{\"name\":\"frank omega\",\"dob\":\"01-08-1978\",\"phone\":\"+5673885674\"}}    |\n",
      "|{\"personal_data\":{\"name\":\"gaddiom tom\",\"dob\":\"01-09-1992\",\"phone\":\"+6754377779\"}}    |\n",
      "+-------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_restructured.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b762f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path for JSON file\n",
    "output_path = \"personal_data.json\"\n",
    "\n",
    "# Write DataFrame to JSON file\n",
    "df_restructured.write.json(output_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95793e0-4ba5-4c58-9538-7c4f981c6402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
